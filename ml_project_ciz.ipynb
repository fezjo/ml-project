{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRzyoboBE/uhKhRH654dAT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fezjo/ml-project/blob/master/ml_project_ciz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXOqfWtiWh2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o8DwGNFJ42-"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "\n",
        "vocab_size = 26*26\n",
        "\n",
        "# vectorize layer adapt to bigrams\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "layers.TextVectorization(\n",
        "    ngrams=(2,),\n",
        "    output_sequence_length=???,)\n",
        ")\n",
        "layers.Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=???,) \n",
        "layers.Dropout(0.25)\n",
        "3,4,5 -> layers.Conv2D(\n",
        "layers.Activation(activations.selu)\n",
        "layers.MaxPooling1D(\n",
        "layers.Dense(300, activation=activations.softmax)\n",
        "layers.Dense(authors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# Input layer for string data\n",
        "inputs = keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "print(inputs.outpu\n",
        "\n",
        "# Preprocessing layer\n",
        "# Use the TextVectorization layer to tokenize the input string based on bigrams\n",
        "preprocessed = keras.layers.TextVectorization(ngrams=(2,), output_sequence_length=200)(inputs)\n",
        "\n",
        "# Embedding layer\n",
        "max_vocab_size = 26**2 + 1\n",
        "embedding_dim = 400\n",
        "embedding = keras.layers.Embedding(max_vocab_size, embedding_dim)(preprocessed) # TODO regularizer\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "dropped = keras.layers.Dropout(0.3)(embedding)\n",
        "\n",
        "# Create 3 parallel Conv1D layers with kernel sizes of 3, 4, and 5\n",
        "conv_input = dropped\n",
        "n_conv_filters = 500\n",
        "convs = [\n",
        "    keras.layers.Conv2D(\n",
        "        filters=n_conv_filters,\n",
        "        kernel_size=(ks, embedding_dim),\n",
        "        activation=\"selu\")(conv_input)\n",
        "    for ks in (3, 4, 5)\n",
        "]\n",
        "\n",
        "# Max pooling layer\n",
        "pooled = [keras.layers.GlobalMaxPooling1D()(conv) for conv in convs]\n",
        "\n",
        "# Concatenate the outputs of the parallel Conv1D layers\n",
        "concatenated = keras.layers.Concatenate()(pooled)\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "dropped = keras.layers.Dropout(0.3)(concatenated)\n",
        "\n",
        "# Add a dense layer\n",
        "dense = keras.layers.Dense(units=300, activation=\"relu\")(dropped)\n",
        "\n",
        "# Output layer\n",
        "outputs = keras.layers.Dense(units=1, activation=\"softmax\")(dense)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "dwVDYD6ZeWcM",
        "outputId": "cf8fa89a-6eda-46e9-f874-4fcbb09706d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-868ad0c4853c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mconv_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mn_conv_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m convs = [\n\u001b[0m\u001b[1;32m     24\u001b[0m     keras.layers.Conv2D(\n\u001b[1;32m     25\u001b[0m         \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_conv_filters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-868ad0c4853c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mn_conv_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m convs = [\n\u001b[0;32m---> 24\u001b[0;31m     keras.layers.Conv2D(\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_conv_filters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    229\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                          \u001b[0;34mf'expected min_ndim={spec.min_ndim}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d_2\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 200, 400)"
          ]
        }
      ]
    }
  ]
}