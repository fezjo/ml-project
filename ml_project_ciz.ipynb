{"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObDo/bia8IHKn6q0WVR816","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/fezjo/ml-project/blob/master/ml_project_ciz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"!wget https://github.com/fezjo/ml-project/raw/master/chat_history.zip\n!unzip -o -Pfmfilords chat_history.zip\n!pip install unidecode","metadata":{"id":"oXOqfWtiWh2G","outputId":"3da28184-8b0c-4edb-aaac-9357a081a6ae","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-01-31T12:57:00.824459Z","iopub.execute_input":"2023-01-31T12:57:00.825045Z","iopub.status.idle":"2023-01-31T12:57:13.090595Z","shell.execute_reply.started":"2023-01-31T12:57:00.824920Z","shell.execute_reply":"2023-01-31T12:57:13.089456Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-01-31 12:57:01--  https://github.com/fezjo/ml-project/raw/master/chat_history.zip\nResolving github.com (github.com)... 140.82.113.4\nConnecting to github.com (github.com)|140.82.113.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/fezjo/ml-project/master/chat_history.zip [following]\n--2023-01-31 12:57:02--  https://raw.githubusercontent.com/fezjo/ml-project/master/chat_history.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2804699 (2.7M) [application/zip]\nSaving to: ‚Äòchat_history.zip.8‚Äô\n\nchat_history.zip.8  100%[===================>]   2.67M  --.-KB/s    in 0.06s   \n\n2023-01-31 12:57:02 (41.3 MB/s) - ‚Äòchat_history.zip.8‚Äô saved [2804699/2804699]\n\nArchive:  chat_history.zip\n  inflating: chat_history.json       \nRequirement already satisfied: unidecode in /opt/conda/lib/python3.7/site-packages (1.3.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef plot_history(history):\n  dpi = 100\n  plt.figure(dpi=dpi)\n  plt.plot(history.history['loss'], label='training loss')\n  plt.plot(history.history.get('val_loss', []), label='validation loss')\n  plt.legend(loc='best')\n\n  plt.figure(dpi=dpi)\n  plt.plot(history.history['accuracy'], label='train accuracy')\n  plt.plot(history.history.get('val_accuracy', []), label='validation accuracy')\n  plt.legend(loc='best')\n  plt.show()","metadata":{"id":"gy0Pa5vyTsIx","execution":{"iopub.status.busy":"2023-01-31T12:57:13.094174Z","iopub.execute_input":"2023-01-31T12:57:13.094497Z","iopub.status.idle":"2023-01-31T12:57:13.101744Z","shell.execute_reply.started":"2023-01-31T12:57:13.094467Z","shell.execute_reply":"2023-01-31T12:57:13.100244Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import json\n\nwith open(\"chat_history.json\") as chf:\n  data = json.load(chf)","metadata":{"id":"gdGwg6ZWHSw9","execution":{"iopub.status.busy":"2023-01-31T12:57:13.103257Z","iopub.execute_input":"2023-01-31T12:57:13.103640Z","iopub.status.idle":"2023-01-31T12:57:13.882639Z","shell.execute_reply.started":"2023-01-31T12:57:13.103604Z","shell.execute_reply":"2023-01-31T12:57:13.881538Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from unidecode import unidecode\n\nauthor_blacklist = {\"PollBot\", \"Dartboi\", \"Telelog\"}\nauthors = dict()\nmessages = []\nfor message in data[\"messages\"]:\n  if message[\"type\"] != \"message\":\n    continue\n  text_entities, author = message[\"text_entities\"], message[\"from\"]\n  if not text_entities or author in author_blacklist:\n    continue\n  text_chunks = []\n  for entity in text_entities:\n    text_chunks.append(entity[\"text\"])\n  text = \"\".join(text_chunks)\n  text = unidecode(text).lower()\n  authors.setdefault(author, len(authors))\n  messages.append((text, authors[author]))\n\nprint(authors)\nprint(messages[:100])","metadata":{"id":"BIIiMiSTIAWg","outputId":"bfc66321-2cbb-405b-ca1f-3fdbd4bf6490","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-01-31T12:57:13.885793Z","iopub.execute_input":"2023-01-31T12:57:13.886218Z","iopub.status.idle":"2023-01-31T12:57:14.154987Z","shell.execute_reply.started":"2023-01-31T12:57:13.886175Z","shell.execute_reply":"2023-01-31T12:57:14.153274Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'Jozef': 0, 'Bohdanator': 1, 'Daniel Oravec': 2, 'Samuel ƒåavoj': 3, 'D√°vid Mi≈°iak': 4, 'Pavol Kebis': 5, 'Jaroslav Pa≈°ka': 6, 'J√°n Priner': 7}\n[('make me admin pls', 0), ('sure :d :d', 1), ('aj mna!!', 2), ('aj mna!!!', 3), ('', 3), ('wtf', 1), ('ono to islo dokelu tak rychlo...', 1), ('neviem, co si cakal, ze sa stane, ked z jozefa spravis admina', 3), ('nespravil som :d :d', 1), ('jaj', 3), ('zabudol som nastavit aby sa to nedialo', 1), (':(', 2), ('genialne', 3), ('kde su vsetky prvacky?', 0), ('co tu robi paska?', 3), ('flexi', 0), ('ani nie', 3), ('tu neexistuje demokracia', 1), ('preco ste dnes neboli v skole?', 2), ('just kidding', 1), ('podme sa bavit o kamenoch', 1), ('lebo som bol na orave', 1), ('rebels', 4), ('pridte na vba231', 0), ('?', 4), ('kedy sa zacina skola?', 0), ('vyzera to tak ze v pondelok', 4), ('cas?', 0), ('asi podla rozvrhu', 4), ('alebo to mecheche otvorenie akademickeho roka', 4), ('neviem ktore z toho', 4), ('vie niekto?', 4), ('podla mna normalne podla rozvrhu. nevidim dovod aby prvakov nadalej zdrzovali formalitami kym ostatny zacnu', 5), ('ostatni', 5), ('pridem proste normalne podla rozvrhu podla mna a basta', 1), ('jop, je to tak', 4), ('fakin algebra o osmej', 4), ('niekto nejde na imatrikulaciu?', 5), ('tvoja mama', 4), ('uooooooou', 1), ('rekt', 1), ('mne sa nechce, ale ked poskytnete peer pressure pojdem', 1), ('', 0), ('sam velky davidb povedal ze sa tam oplati ist', 4), ('aj ked nepovedal rozumne dovody', 4), ('iba ze proste tam sa chodi', 4), ('', 2), ('no akoze neodprezentovali to praave nadsene ti typkovia', 1), ('hm chlapci zoberte si slusne oblecenie, nejake kosele a sako alebo co, ale nedoneste si ziadne mencestraky a tricko, lebo vas odtial vyhodim. oblecte sa slusne, hlavne teda chlapci, dievcatam nemusim nic hovorit', 1), ('to je jedine co si o prezentacii toho pamatam', 1), ('a kravata!', 4), ('ze kosele, fakin oblek! a ziadne tenisky!!!', 4), ('a neopovaz sa prist v tricku', 1), ('lebo ta vyhodim osobne', 1), ('@fezjo dones tam lieskovce pls', 4), ('boli danove podla mna', 1), ('mam este 3', 2), ('prijmi moje hlboke ospravedlnenie', 4), ('a ty chod klacat do kuta', 1), ('viet niekto odfotit ten papier s povinnymi predmetmi?', 2), ('viac prosim!!', 2), ('vdaka', 2), ('fokin dalsie strany :d', 2), ('je to na webe', 3), ('ale on to chcel odfotit', 1), ('no, ads sa kryje s telesnou a foja s programovanim', 1), ('fokin votr pls', 4), ('ads > foja', 4), ('ideme foju?', 2), ('neprebereme to zajtra?', 4), ('ale ja nechcem foju!', 2), ('vsak aj ja vravim ze ads je lepsie', 4), ('madafaka', 4), ('ale mozes mat obe', 2), ('alebo mozes mat sendvic', 4), ('a je to or alebo, nie xor alebo', 4), ('nemozes mat fakin nic lebo sa ti to kryje', 1), ('alebo som hlupy a opravte ma', 1), ('fakin zajtra si to pustime na projektor a pobijeme sa', 4), ('dobre', 1), ('zrezem ta remenom', 1), ('wtf', 4), ('wtf', 1), ('konec totok', 4), ('dajme 100 percent absenciu', 1), ('pezinok', 4), ('kde je pezinok', 1), ('pezinok', 0), ('to je on', 1), ('a na prestavku mame nula celych nula celych nula nula casu', 4), ('potom napiste co hovorite na foju', 1), ('sak tam nemusis chodit a mas zadarmo', 1), ('kul and gud', 0), ('ako pcc++', 0), ('?', 0), ('skoro vsetko maju napisane na webe', 4), ('status?', 0), ('hello world program', 1), ('vy?', 1), ('', 0)]\n","output_type":"stream"}]},{"cell_type":"code","source":"author_activity = [0] * len(authors)\nfor message in messages:\n  author_activity[message[1]] += 1\n\nfor author, activity in zip(authors.items(), author_activity):\n  print(\"{}: {} [{:.2%}]\".format(author, activity, activity / len(messages)))","metadata":{"id":"zXHsu6sUUL4E","outputId":"3311d922-7373-45f5-a491-14b07685e443","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-01-31T12:57:14.157002Z","iopub.execute_input":"2023-01-31T12:57:14.157364Z","iopub.status.idle":"2023-01-31T12:57:14.174322Z","shell.execute_reply.started":"2023-01-31T12:57:14.157327Z","shell.execute_reply":"2023-01-31T12:57:14.173183Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"('Jozef', 0): 17808 [27.98%]\n('Bohdanator', 1): 6326 [9.94%]\n('Daniel Oravec', 2): 6078 [9.55%]\n('Samuel ƒåavoj', 3): 17254 [27.11%]\n('D√°vid Mi≈°iak', 4): 15336 [24.10%]\n('Pavol Kebis', 5): 489 [0.77%]\n('Jaroslav Pa≈°ka', 6): 21 [0.03%]\n('J√°n Priner', 7): 328 [0.52%]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\nml_stats = []\nfor len_fun in (lambda m: len(m[0]), lambda m: len(m[0].split())):\n    message_lengths = np.array(list(map(len_fun, messages)))\n    sml = sorted(message_lengths)\n    ml_avg, ml_std = np.mean(message_lengths), np.std(message_lengths)\n    print(f\"message length / avg: {ml_avg:.2f} / std: {ml_std:.2f}\")\n    for r in (0.5, 0.68, 0.9, 0.95, 0.99, 0.997, 1):\n        i = min(len(sml) - 1, int(len(sml) * r))\n        print(r, sml[i])\n    print()\n    ml_stats.append((ml_avg, ml_std))","metadata":{"id":"KDVs51CU065f","outputId":"161791a6-1663-45d8-8216-6346cd69a0b7","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-01-31T12:57:14.175798Z","iopub.execute_input":"2023-01-31T12:57:14.176256Z","iopub.status.idle":"2023-01-31T12:57:14.274355Z","shell.execute_reply.started":"2023-01-31T12:57:14.176220Z","shell.execute_reply":"2023-01-31T12:57:14.273461Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"message length / avg: 34.47 / std: 60.23\n0.5 23\n0.68 35\n0.9 72\n0.95 98\n0.99 189\n0.997 326\n1 4095\n\nmessage length / avg: 6.31 / std: 8.64\n0.5 4\n0.68 7\n0.9 13\n0.95 18\n0.99 33\n0.997 53\n1 610\n\n","output_type":"stream"}]},{"cell_type":"code","source":"perm = np.random.permutation(len(messages))\nshuffled_messages = [messages[i] for i in perm]\nX, Y = map(lambda k: np.array([m[k] for m in shuffled_messages]), (0, 1))\ntrain_test_ratio = 0.8\nnum_train = int(train_test_ratio * len(X))\nX_train, X_test = np.split(X, [num_train])\nY_train, Y_test = np.split(Y, [num_train])\noutput_shape = len(authors)\n\nprint(X[:100])\nprint(Y[:100])\nprint(X.shape, X_train.shape, X_test.shape)\nprint(Y.shape, Y_train.shape, Y_test.shape)","metadata":{"id":"h7N6bFEkPc_w","outputId":"b30bae92-0fa3-496a-e1f8-b19d7cd5d915","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-01-31T12:57:14.276038Z","iopub.execute_input":"2023-01-31T12:57:14.276453Z","iopub.status.idle":"2023-01-31T12:57:15.040753Z","shell.execute_reply.started":"2023-01-31T12:57:14.276418Z","shell.execute_reply":"2023-01-31T12:57:15.039713Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['ake ine su?' 'cho_bot' 'nice one' 'lebo som to vygooglil'\n 'vtedy neni uplne?' 'stale iba cavoj keca'\n 'ale vravel ze ked bude viac ludi, daju to na etapy, ze jedni budu odpovedat a oatatni pojdu zatial na obed. nie?'\n 'ano' 'hrozne vela prikladov tam je'\n 'to znie dost ze to vnima negativne :d' 'asi hej' 'idk' 'dakujem'\n 'davali dnes na tej foja aj nejaku teoriu?'\n 'ako by sa to navstivenie enforcovalo?'\n 'to by platilo aj keby sme mali obaja 0' 'teraz som zmatany' 'ci?'\n 'uz teraz ma z toho boli hlava' 'a kde beriete tieto spravy?'\n 'fpro na 1.5? sialene' 'pekne' 'ale ja mam extremne tazky rp'\n 'takze vies spravit take nieco, ze nechas ten pte strom viac menej prazdny a ked pride page fault, tak vyrobis tu vetvu, ktoru treba'\n 'ako povies to co bezi priamo na pocitaci'\n 'preco mam pocit, ze budeme programovat testovac?' 'ja som nie a on ok'\n 'ale ja nechcem foju!'\n 'proste som influencer na instagrame a vsetci si ma napisu ako sprostredkovatela'\n 'ja som akoze aj slnieckar aj vsetko, ale toto by ma nenapadlo :d\\nhttps://www.zdnet.com/article/github-to-replace-master-with-alternative-term-to-avoid-slavery-references/'\n 'aj na webe to je' 'chcel som 10^10 !!!!!!!'\n 'ano vsetko sa to robi v spravnom poradi' 'aky smajlik je ?:-' 'repeatre'\n 'si masivny'\n 'wtf vy ste mi editli spravu? som si takmer isty ze v nej bol preklep'\n 'on pouzil ze obraz nebol cf?' 'fokchin' 'da sa to spravit v o(1)?'\n 'jasne' 'este som skoro ani nezacal' 'vsak tam je' 'kedy ides ty?'\n 'fakin htop' 'asi nie' 'mali by sme tam ist buduci tyzden'\n 'asi aby to bolo otravnejsie' '\"na kazdej sipke mozeme mat interface\"'\n 'vlastne 1 (spolocenske aspekty alebo extremne programovanie)'\n 'kredity zadarmo' 'zverejnim 2d spalene palacinkove cislo 1'\n 'kvant je 20.'\n 'ides na stranku ankety a je tam masivacky button vysledky'\n 'mne je zima, som indisponovany' 'preco je do 23.'\n 'vsak toto, ze nechcem aby si to zbytocne rozpraval'\n 'take nieco som pocul, to muselo byt super'\n 'ten matus co mal trivialnu ustnu mal 100% na pisomnej?'\n '\"zneguj implikaciu\"' 'jozef produkuje value iba ked ho ostatni uvidia'\n '(nie ze by to bola chyba toho casu alebo tak xd xd)'\n 'tvoja mamka, aj tak som sa pri tom 4krat pomylil'\n 'ale tie velmi pomale som nenechal bezat' 'no a fakin co'\n 'ja vam ho kludne poslem lol' 'nieco take, mozno 4' 'faaak'\n 'takze ked mas teoriu a nejaku strukturu, tak ta struktura sa vola model, ked v nej plati ta teoria'\n 'perfekt' 'proste kazdu vetu si musim pustit 5 krat' 'akssant'\n 'inak by ste boli na tej uib ustnej?'\n \"no asi vacsi ako ked tam teraz bude mrtvy link'\"\n 'asi nie, lebo tusim iba prva odpoved to bola' 'mozno'\n 'velky kamen mi zo srdca spadol'\n 'rozmyslam ci to nie je nahodou aj tak jednoznacne' 'nevies?'\n 'vidis, zase to mas skor' 'c by som mal' 'massification'\n 'https://docs.google.com/forms/d/e/1faipqlschbjcevkxs98e7oxicxufprhgbbqnvm5dd89rogg2ie73plg/formresponse'\n 'wow trivialnejsie to uz nemohlo byt'\n 'ja by som mozno isiel znova na tea' 'fx' 'ano' 'hypertext?'\n 'musi ist na vlak predsa'\n 'a viem ze keby som zjedol vela ryb tak ich budem mat ale na to sa nechodi do restauracii, to si musim zvyknut doma'\n 'nebudes mat pracu'\n 'https://www.reddit.com/r/i3wm/comments/mvfwui/is_this_poem_fine\\ntaketo fajne basne sa naucte pisat'\n 'jooj, to neviem ci porazis tych koscelanskeho'\n 'este skoncis v skupine ktora sa kryje s kryptom'\n 'proste mi staci 8b neviem co tam chces pchat :d'\n 'skoda ze som lepsi, porazil som vysoky level' 'alebo nieco take'\n 'ale tazke je to' 'ml?' 'si genius']\n[0 3 3 1 4 0 4 0 4 4 3 3 2 5 0 3 0 0 1 0 4 0 0 3 0 2 2 2 0 4 4 3 1 3 3 3 3\n 2 0 0 3 4 0 2 4 3 0 3 3 0 4 0 0 4 3 3 0 2 0 2 3 1 1 0 4 1 1 4 3 3 0 1 3 3\n 4 3 0 4 0 4 5 4 5 3 0 3 3 3 2 0 0 4 4 3 3 0 3 0 0 3]\n(63640,) (50912,) (12728,)\n(63640,) (50912,) (12728,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\n\n# Use the TextVectorization layer to tokenize the input string based on bigrams\nsequence_dim_from_stats = lambda stat: int(stat[0] + 2 * stat[1]) * 2\nbigram_sequence_dim = sequence_dim_from_stats(ml_stats[0])\npreprocessing_char = keras.layers.TextVectorization(\n    standardize=None,\n    split=tf.strings.bytes_split,\n    ngrams=2,\n    output_sequence_length=bigram_sequence_dim)\npreprocessing_char.adapt(X_train)\n\nword_sequence_dim = sequence_dim_from_stats(ml_stats[1])\npreprocessing_word = keras.layers.TextVectorization(\n    ngrams=2,\n    output_sequence_length=word_sequence_dim,\n    max_tokens=5000)\npreprocessing_word.adapt(X_train)\n\n# Input layer for string data\ninputs = keras.layers.Input(shape=(1,), dtype=tf.string)\n\nchannels = []\nfor preprocessing in (preprocessing_char, preprocessing_word):\n    # Preprocessing layer\n    layer = preprocessing(inputs)\n\n    # Embedding layer\n    max_vocab_size = len(preprocessing.get_vocabulary()) + 1\n    print(f\"Vocabulary size: {max_vocab_size}\")\n    embedding_dim = 200\n    layer = keras.layers.Embedding(\n        input_dim=max_vocab_size,\n        output_dim=embedding_dim,\n    #     embeddings_regularizer=\"l1\",\n    )(layer)\n\n    # Add a dropout layer to prevent overfitting\n    layer = keras.layers.Dropout(rate=0.25)(layer)\n\n    # Add dimension for channel needed by convolution\n    layer = keras.layers.Reshape(target_shape=(*layer.shape[-2:], 1))(layer)\n\n    # # Create 3 parallel branches for convolution with varying window widths\n    n_conv_filters = 400 # TODO\n    parent_layer = layer\n    child_layers = []\n    for ks in (3, 4, 5):\n        layer = parent_layer\n\n        layer = keras.layers.Conv2D(\n            filters=n_conv_filters,\n            kernel_size=(ks, embedding_dim),\n            activation=\"selu\")(layer)\n\n        # Max pooling layer\n        layer = keras.layers.GlobalMaxPooling2D()(layer)\n        child_layers.append(layer)\n\n    # Concatenate the outputs of the parallel Conv1D layers\n    layer = keras.layers.Concatenate()(child_layers)\n    \n    channels.append(layer)\n\n\n# Concatenate the outputs of the char and word channels\nlayer = keras.layers.Concatenate()(channels)\n\n# # Add a dropout layer to prevent overfitting\nlayer = keras.layers.Dropout(rate=0.5)(layer)\n\n# # Add a dense layer\n# layer = keras.layers.Dense(units=300, activation=\"relu\")(layer)\n\n# Output layer\noutputs = keras.layers.Dense(units=output_shape, activation=\"softmax\")(layer)\n\n# Create the model\nmodel = keras.Model(inputs=inputs, outputs=outputs)\n\n# Compile the model\nmodel.compile(\n    optimizer=keras.optimizers.Adam(0.0002),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwVDYD6ZeWcM","outputId":"884cd821-03ec-4166-f376-e0b93ab6b5a0","execution":{"iopub.status.busy":"2023-01-31T12:57:15.043454Z","iopub.execute_input":"2023-01-31T12:57:15.044241Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2023-01-31 12:57:16.920112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:16.930502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:16.931222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:16.932993: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-31 12:57:16.933342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:16.934036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:16.934677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:17.609577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:17.610463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:17.611129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 12:57:17.611782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2023-01-31 12:57:18.185051: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"for preprocessing in (preprocessing_char, preprocessing_word):\n    print(preprocessing.get_vocabulary()[:100])","metadata":{"id":"oQ6YmxqkkW_4","outputId":"57c3fe91-3738-4a34-cf4c-54d269985433","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_text = \"fakin ak si nic nedas, tak PON UTO PIA mas???!? cely den na pracu a este streda poobede :D üëç @fezjo\"\n\ninp = model.input                                           # input placeholder\nmodel_outputs = [layer.output for layer in model.layers]          # all layer outputs\nfunctor = lambda outputs: keras.backend.function(inp, outputs)   # evaluation function\n\n# Testing\nfor output in model_outputs[:3]:\n  print(functor([output])(np.array([sample_text])))","metadata":{"id":"QeABB9LmasR9","outputId":"d9e595c7-c7a3-46f4-aace-51d3cdb9d57c","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(**{\n    \"x\": X_train,\n    \"y\": keras.utils.to_categorical(Y_train),\n    \"epochs\": 20,\n    \"batch_size\": 512,\n    \"validation_split\": 0.10,\n    \"verbose\": 1,\n    })\n\nplot_history(history)","metadata":{"id":"33v51oypOQxY","outputId":"2a7fa70d-23fb-4b29-ed7c-b923b444f84b","colab":{"base_uri":"https://localhost:8080/","height":595},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(authors)\nsample_num = 100\nprediction = model.predict(X_test[:sample_num])\nfor pred, x, y in zip(prediction, X_test, Y_test):\n    py = pred.argmax()\n    print(f\"correct={y==py} real={y} pred={py} [{pred}] {x}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_score = model.evaluate(X_train, tf.keras.utils.to_categorical(Y_train))\nprint(\"\\n\\ntrain loss: {} | train acc: {}\\n\".format(train_score[0], train_score[1]))\n\ntest_score = model.evaluate(X_test, tf.keras.utils.to_categorical(Y_test))\nprint(\"\\n\\ntest loss: {} | test acc: {}\".format(test_score[0], test_score[1]))","metadata":{"id":"PGuGYSdyzP0z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nEpoch 1/10\n716/716 [==============================] - 27s 36ms/step - loss: 1.4964 - accuracy: 0.3837 - val_loss: 1.4383 - val_accuracy: 0.4183\nEpoch 2/10\n716/716 [==============================] - 25s 36ms/step - loss: 1.4131 - accuracy: 0.4310 - val_loss: 1.3970 - val_accuracy: 0.4354\nEpoch 3/10\n716/716 [==============================] - 25s 36ms/step - loss: 1.3427 - accuracy: 0.4655 - val_loss: 1.3826 - val_accuracy: 0.4470\nEpoch 4/10\n716/716 [==============================] - 25s 36ms/step - loss: 1.2733 - accuracy: 0.4990 - val_loss: 1.3885 - val_accuracy: 0.4440\nEpoch 5/10\n716/716 [==============================] - 25s 35ms/step - loss: 1.1959 - accuracy: 0.5339 - val_loss: 1.3993 - val_accuracy: 0.4521\nEpoch 6/10\n716/716 [==============================] - 25s 35ms/step - loss: 1.1183 - accuracy: 0.5708 - val_loss: 1.4258 - val_accuracy: 0.4544\nEpoch 7/10\n716/716 [==============================] - 25s 35ms/step - loss: 1.0404 - accuracy: 0.5998 - val_loss: 1.4407 - val_accuracy: 0.4487\nEpoch 8/10\n716/716 [==============================] - 25s 35ms/step - loss: 0.9775 - accuracy: 0.6283 - val_loss: 1.4890 - val_accuracy: 0.4476\nEpoch 9/10\n716/716 [==============================] - 25s 35ms/step - loss: 0.9131 - accuracy: 0.6558 - val_loss: 1.5166 - val_accuracy: 0.4470\nEpoch 10/10\n716/716 [==============================] - 25s 35ms/step - loss: 0.8509 - accuracy: 0.6859 - val_loss: 1.5764 - val_accuracy: 0.4550\n```","metadata":{}}]}