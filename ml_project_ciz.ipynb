{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObDo/bia8IHKn6q0WVR816",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fezjo/ml-project/blob/master/ml_project_ciz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/fezjo/ml-project/raw/master/chat_history.zip\n",
        "!unzip -Pputpassword chat_history.zip\n",
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "oXOqfWtiWh2G",
        "outputId": "3da28184-8b0c-4edb-aaac-9357a081a6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-30 22:49:22--  https://github.com/fezjo/ml-project/raw/master/chat_history.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fezjo/ml-project/master/chat_history.zip [following]\n",
            "--2023-01-30 22:49:23--  https://raw.githubusercontent.com/fezjo/ml-project/master/chat_history.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2804699 (2.7M) [application/zip]\n",
            "Saving to: â€˜chat_history.zip.10â€™\n",
            "\n",
            "chat_history.zip.10 100%[===================>]   2.67M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-01-30 22:49:23 (291 MB/s) - â€˜chat_history.zip.10â€™ saved [2804699/2804699]\n",
            "\n",
            "Archive:  chat_history.zip\n",
            "   skipping: chat_history.json       incorrect password\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.8/dist-packages (1.3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_history(history):\n",
        "  dpi = 100\n",
        "  plt.figure(dpi=dpi)\n",
        "  plt.plot(history.history['loss'], label='training loss')\n",
        "  plt.plot(history.history.get('val_loss', []), label='validation loss')\n",
        "  plt.legend(loc='best')\n",
        "\n",
        "  plt.figure(dpi=dpi)\n",
        "  plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "  plt.plot(history.history.get('val_accuracy', []), label='validation accuracy')\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "gy0Pa5vyTsIx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"chat_history.json\") as chf:\n",
        "  data = json.load(chf)"
      ],
      "metadata": {
        "id": "gdGwg6ZWHSw9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unidecode import unidecode\n",
        "\n",
        "author_blacklist = {\"PollBot\", \"Dartboi\", \"Telelog\"}\n",
        "authors = dict()\n",
        "messages = []\n",
        "for message in data[\"messages\"]:\n",
        "  if message[\"type\"] != \"message\":\n",
        "    continue\n",
        "  text_entities, author = message[\"text_entities\"], message[\"from\"]\n",
        "  if not text_entities or author in author_blacklist:\n",
        "    continue\n",
        "  text_chunks = []\n",
        "  for entity in text_entities:\n",
        "    text_chunks.append(entity[\"text\"])\n",
        "  text = \"\".join(text_chunks)\n",
        "  text = unidecode(text).lower()\n",
        "  authors.setdefault(author, len(authors))\n",
        "  messages.append([text, authors[author]])\n",
        "\n",
        "print(authors)\n",
        "print(messages[:100])"
      ],
      "metadata": {
        "id": "BIIiMiSTIAWg",
        "outputId": "bfc66321-2cbb-405b-ca1f-3fdbd4bf6490",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Jozef': 0, 'Bohdanator': 1, 'Daniel Oravec': 2, 'Samuel ÄŒavoj': 3, 'DÃ¡vid MiÅ¡iak': 4, 'Pavol Kebis': 5, 'Jaroslav PaÅ¡ka': 6, 'JÃ¡n Priner': 7}\n",
            "[['make me admin pls', 0], ['sure :d :d', 1], ['aj mna!!', 2], ['aj mna!!!', 3], ['', 3], ['wtf', 1], ['ono to islo dokelu tak rychlo...', 1], ['neviem, co si cakal, ze sa stane, ked z jozefa spravis admina', 3], ['nespravil som :d :d', 1], ['jaj', 3], ['zabudol som nastavit aby sa to nedialo', 1], [':(', 2], ['genialne', 3], ['kde su vsetky prvacky?', 0], ['co tu robi paska?', 3], ['flexi', 0], ['ani nie', 3], ['tu neexistuje demokracia', 1], ['preco ste dnes neboli v skole?', 2], ['just kidding', 1], ['podme sa bavit o kamenoch', 1], ['lebo som bol na orave', 1], ['rebels', 4], ['pridte na vba231', 0], ['?', 4], ['kedy sa zacina skola?', 0], ['vyzera to tak ze v pondelok', 4], ['cas?', 0], ['asi podla rozvrhu', 4], ['alebo to mecheche otvorenie akademickeho roka', 4], ['neviem ktore z toho', 4], ['vie niekto?', 4], ['podla mna normalne podla rozvrhu. nevidim dovod aby prvakov nadalej zdrzovali formalitami kym ostatny zacnu', 5], ['ostatni', 5], ['pridem proste normalne podla rozvrhu podla mna a basta', 1], ['jop, je to tak', 4], ['fakin algebra o osmej', 4], ['niekto nejde na imatrikulaciu?', 5], ['tvoja mama', 4], ['uooooooou', 1], ['rekt', 1], ['mne sa nechce, ale ked poskytnete peer pressure pojdem', 1], ['', 0], ['sam velky davidb povedal ze sa tam oplati ist', 4], ['aj ked nepovedal rozumne dovody', 4], ['iba ze proste tam sa chodi', 4], ['', 2], ['no akoze neodprezentovali to praave nadsene ti typkovia', 1], ['hm chlapci zoberte si slusne oblecenie, nejake kosele a sako alebo co, ale nedoneste si ziadne mencestraky a tricko, lebo vas odtial vyhodim. oblecte sa slusne, hlavne teda chlapci, dievcatam nemusim nic hovorit', 1], ['to je jedine co si o prezentacii toho pamatam', 1], ['a kravata!', 4], ['ze kosele, fakin oblek! a ziadne tenisky!!!', 4], ['a neopovaz sa prist v tricku', 1], ['lebo ta vyhodim osobne', 1], ['@fezjo dones tam lieskovce pls', 4], ['boli danove podla mna', 1], ['mam este 3', 2], ['prijmi moje hlboke ospravedlnenie', 4], ['a ty chod klacat do kuta', 1], ['viet niekto odfotit ten papier s povinnymi predmetmi?', 2], ['viac prosim!!', 2], ['vdaka', 2], ['fokin dalsie strany :d', 2], ['je to na webe', 3], ['ale on to chcel odfotit', 1], ['no, ads sa kryje s telesnou a foja s programovanim', 1], ['fokin votr pls', 4], ['ads > foja', 4], ['ideme foju?', 2], ['neprebereme to zajtra?', 4], ['ale ja nechcem foju!', 2], ['vsak aj ja vravim ze ads je lepsie', 4], ['madafaka', 4], ['ale mozes mat obe', 2], ['alebo mozes mat sendvic', 4], ['a je to or alebo, nie xor alebo', 4], ['nemozes mat fakin nic lebo sa ti to kryje', 1], ['alebo som hlupy a opravte ma', 1], ['fakin zajtra si to pustime na projektor a pobijeme sa', 4], ['dobre', 1], ['zrezem ta remenom', 1], ['wtf', 4], ['wtf', 1], ['konec totok', 4], ['dajme 100 percent absenciu', 1], ['pezinok', 4], ['kde je pezinok', 1], ['pezinok', 0], ['to je on', 1], ['a na prestavku mame nula celych nula celych nula nula casu', 4], ['potom napiste co hovorite na foju', 1], ['sak tam nemusis chodit a mas zadarmo', 1], ['kul and gud', 0], ['ako pcc++', 0], ['?', 0], ['skoro vsetko maju napisane na webe', 4], ['status?', 0], ['hello world program', 1], ['vy?', 1], ['', 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "author_activity = [0] * len(authors)\n",
        "for message in messages:\n",
        "  author_activity[message[1]] += 1\n",
        "\n",
        "for author, activity in zip(authors.items(), author_activity):\n",
        "  print(\"{}: {} [{:.2%}]\".format(author, activity, activity / len(messages)))"
      ],
      "metadata": {
        "id": "zXHsu6sUUL4E",
        "outputId": "3311d922-7373-45f5-a491-14b07685e443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Jozef', 0): 17808 [27.98%]\n",
            "('Bohdanator', 1): 6326 [9.94%]\n",
            "('Daniel Oravec', 2): 6078 [9.55%]\n",
            "('Samuel ÄŒavoj', 3): 17254 [27.11%]\n",
            "('DÃ¡vid MiÅ¡iak', 4): 15336 [24.10%]\n",
            "('Pavol Kebis', 5): 489 [0.77%]\n",
            "('Jaroslav PaÅ¡ka', 6): 21 [0.03%]\n",
            "('JÃ¡n Priner', 7): 328 [0.52%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "message_lengths = np.array(list(map(lambda m: len(m[0]), messages)))\n",
        "ml_avg, ml_std = np.mean(message_lengths), np.std(message_lengths)\n",
        "print(f\"message length / avg: {ml_avg:.2f} / std: {ml_std:.2f}\")"
      ],
      "metadata": {
        "id": "KDVs51CU065f",
        "outputId": "161791a6-1663-45d8-8216-6346cd69a0b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message length / avg: 34.47 / std: 60.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_messages = np.random.permutation(messages)\n",
        "X, Y = map(lambda k: np.array([m[k] for m in shuffled_messages]), (0, 1))\n",
        "train_test_ratio = 0.8\n",
        "num_train = int(train_test_ratio * len(X))\n",
        "X_train, X_test = np.split(X, [num_train])\n",
        "Y_train, Y_test = np.split(Y, [num_train])\n",
        "output_shape = len(authors)\n",
        "\n",
        "print(X[:100])\n",
        "print(Y[:100])\n",
        "print(X.shape, X_train.shape, X_test.shape)\n",
        "print(Y.shape, Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "id": "h7N6bFEkPc_w",
        "outputId": "b30bae92-0fa3-496a-e1f8-b19d7cd5d915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lol' 'nefunguje mi to'\n",
            " 'pondelok 8 piatok 8 a este 4 niekam musim napchat'\n",
            " 'mozete sa mi vysmiat, budem mat 0 za du z foje btw'\n",
            " 'a potom bohdan povedal tau gama :d'\n",
            " 'checkpointing\\n...\\n1. zapis vsetky log-zaznamy na disk'\n",
            " ' 1. t vx f(g(x)) = x                               s+  \\n 2.*t 3x 3y (g(x) = g(y) /\\\\ !x = y)                s+  \\n 3.*t 3y (g(a) = g(y) /\\\\ !a = y)                   d2 {x -> a}\\n 4.*t (g(a) = g(b) /\\\\ !a = b)                      d3 {y -> b}\\n 5. t g(a) = g(b)                                  a4 (prva cast alfy)\\n 6.*t !a = b                                       a4 (druha cast alfy)\\n 7. f a = b                                        a6  \\n 8. t f(g(a)) = a                                  j1 {x -> a}\\n 9. t f(g(b)) = b                                  j1 {x -> b}\\n10. t f(g(a)) = b                                  take to pravidlo pre tabla s rovnostou, ze ked a = b, tak mozem niekde za a substituovat b podla 5. do 9. {g(b) -> g(a)}\\n11. t a = b                                        to iste pravidlo ako o riadok vyssie, ale teraz do 10. substituujeme podla 8. {f(g(a)) -> a}\\n12. * 7, 11'\n",
            " 'a v komentaroch je na to otazka a je povedane ze musi byt aspon jeden znak za tym'\n",
            " '@danza3' 'joooooooooooooooooooooooooooooj' 'mate to?'\n",
            " 'uz mesiac hotovo?'\n",
            " 'to si nejak veris, ked si si isty ze mas aspon 50/60... ja som imho vyriesil vsetko (s chybou v tej ano/nie) a vobec nie som az tak presvedceny ze to bude aspon 50, vies ako, niekedy strhavaju aj za preklepy a tak :d'\n",
            " 'chcem skolu, kedy nam vsetko nalozia naraz'\n",
            " 'mam ti poslat nejaky gaycoin?' 'kolko mas stavov?'\n",
            " 'fakt nechcem analyzu 3 :d'\n",
            " 'poobede je normalne uib, a tiez midterm fpro, a inak nic'\n",
            " 'ale proste mozno taka je semantika, ze ta nocna extenduje normalnu, ale sipka ide od extendovaneho k extendujucemu'\n",
            " 'a nikto iny nevie ako' 'ja mam 16.5 a chyba mi 13.5 za du'\n",
            " 'pol co ma takto paste hore ano dame bratislavakom' 'ml'\n",
            " 'su 2 fakin opravne a jeden je pocas adsiek?'\n",
            " 'prepni prosim na anime opening playlist'\n",
            " 'masivne som sa osprchoval a zozral pol marlenky'\n",
            " 'to by platilo aj keby sme mali obaja 0'\n",
            " 'to je tazka otazka ked neviem ako pojdu ostatni' 'nie'\n",
            " 'co sa prave deje?' 'ako vnimate koniec semestra?'\n",
            " 'to uz si davno mal spravit' 'oo ano'\n",
            " 'len ja som si presiel tu prvu prezentaciu, potom som si spomenul ze dano pisal poznamky, tak som si ju presiel celu znova ale asi nic mi to nepomoholo'\n",
            " 'klatikova?' 'stiahnuty kakacik more like' 'mohli by nam predlzit'\n",
            " 'toto nie je pravda' 'ale stale tam je'\n",
            " 'continuum hypothesis je tusim nezavisla od zfc'\n",
            " 'ale teda slidy su na stranke' 'asi takto'\n",
            " 'bude smutny ked mu to poslem zajtra?' 'aky email?'\n",
            " 'najde ci sa tu nachadza zastavka na trase kde jozef nastupil\\ntoto je ta narocna operacia'\n",
            " 'ja som myslel ze na firefoxe ide' 'nie' 'jaj vlastne hej'\n",
            " 'som smutny na tychto hodinach' 'idem si dat nap, napiste result'\n",
            " 'proste [1..10000000000]!!9999999999' 'debiliak'\n",
            " 'hmm, no ak to tak je, tak sme to uz zmeskali :d'\n",
            " 'a ja ho pouzivam casto' 'posli' 'co ine' '@samuelcavoj'\n",
            " 'filesystem uz ma hotovy' 'tie za chyby v skriptach'\n",
            " 'tu druhu polku som osobne ani necital' 'mal som tam neskutocnu chybu'\n",
            " 'nice' 'yes' 'myslim ze ~2000' 'nidce' 'bc. (!!!) matej zajo !!! '\n",
            " 'netusim' 'obrvoske' 'kedy su?' 'prihlasil som sa sam' 'znicene'\n",
            " 'a napisal som tam ze kedze mam fakin hypermasivnu gramatiku, tak sa mi nechce vypisovat tu delta funkciu'\n",
            " 'asi si dam python pre zmenu, len potom sa mi jozo a kuko vysmeju ze je to pomale'\n",
            " 'what' ':o' 'ani tam' 'vsak si vybavme osobne cviko vo stvrtok'\n",
            " 'nie je samostatna cast pisomka, ale striktne vzate nic by mu nebranilo tie iste otazky pouzit ako pisomku, lebo nebolo to ze \"tu je tema a povedz o nej vsetko\", ale normalne ulohy'\n",
            " 'jaj no tak to je :d' 'noo' 'akoze videl som ten dokaz pred hodinou' '?'\n",
            " 'i understand that we are engaging in a role-playing game (rpg) and that you are pretending that i am a vast artificial intelligence with a galactic brain and the ability to perceive the fifth dimension. however, it is important to remember that this is purely fictional and that i am actually just a computer program designed to provide information and answer questions to the best of my ability, based on the data and knowledge that i have been trained on.'\n",
            " 'nikde tam nehovorim o celom gui iba o jeho castiach'\n",
            " 'milujem tento jazyk, naozaj fantasticku filozofiu ma...'\n",
            " 'dajte sem jozo counter pliz' '/stop@samuelcavoj'\n",
            " 'https://clbin.com/t4fn3' 'ja som to musel robit pri pow aj div' 'oha'\n",
            " 'toto znie uveritelne' 'stale nic' 'ano' 'netusim'\n",
            " 'imho este pockajme do zajtra, ze ci k tomu nepovie nejake pokyny' ':ddd'\n",
            " 'ale vsetky vety su dokazane' 'primitivna'\n",
            " 'ja som si vymyslel ze sa najprv skusim naucit nez poslem proposal, nech aj viem co sa da robit'\n",
            " 'davidko ked uz ludom hovoris riesenia tak povedz mne ako sa ma robit os']\n",
            "['2' '2' '1' '1' '2' '0' '2' '0' '3' '4' '0' '0' '4' '0' '2' '3' '3' '4'\n",
            " '4' '3' '3' '1' '0' '0' '3' '4' '3' '2' '0' '2' '0' '4' '0' '0' '0' '1'\n",
            " '0' '5' '3' '3' '3' '2' '0' '0' '0' '0' '2' '4' '3' '1' '3' '0' '4' '0'\n",
            " '3' '0' '4' '3' '4' '4' '3' '3' '3' '2' '4' '4' '3' '3' '2' '2' '1' '3'\n",
            " '1' '3' '1' '3' '4' '4' '3' '0' '0' '0' '3' '0' '4' '0' '4' '3' '4' '1'\n",
            " '5' '1' '3' '4' '4' '0' '4' '0' '4' '0']\n",
            "(63640,) (50912,) (12728,)\n",
            "(63640,) (50912,) (12728,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# Use the TextVectorization layer to tokenize the input string based on bigrams\n",
        "bigram_sequence_dim = int(ml_avg + ml_std)\n",
        "preprocessing = keras.layers.TextVectorization(\n",
        "    standardize=None,\n",
        "    split=tf.strings.bytes_split,\n",
        "    ngrams=2,\n",
        "    output_sequence_length=bigram_sequence_dim)\n",
        "preprocessing.adapt(X_train)\n",
        "\n",
        "# Input layer for string data\n",
        "inputs = keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "\n",
        "# Preprocessing layer\n",
        "layer = preprocessing(inputs)\n",
        "\n",
        "# Embedding layer\n",
        "max_vocab_size = len(preprocessing.get_vocabulary()) + 1\n",
        "print(f\"Vocabulary size: {max_vocab_size}\")\n",
        "embedding_dim = 200\n",
        "layer = keras.layers.Embedding(input_dim=max_vocab_size, output_dim=embedding_dim)(layer) # TODO regularizer\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "layer = keras.layers.Dropout(rate=0.3)(layer)\n",
        "\n",
        "# Add dimension for channel needed by convolution\n",
        "layer = keras.layers.Reshape(target_shape=(*layer.shape[-2:], 1))(layer)\n",
        "\n",
        "# # Create 3 parallel branches for convolution with varying window widths\n",
        "n_conv_filters = 20 # TODO\n",
        "parent_layer = layer\n",
        "child_layers = []\n",
        "for ks in (3, 4, 5):\n",
        "    layer = parent_layer\n",
        "\n",
        "    layer = keras.layers.Conv2D(\n",
        "        filters=n_conv_filters,\n",
        "        kernel_size=(ks, embedding_dim),\n",
        "        activation=\"selu\")(layer)\n",
        "    \n",
        "    # Max pooling layer\n",
        "    layer = keras.layers.GlobalMaxPooling2D()(layer)\n",
        "    child_layers.append(layer)\n",
        "\n",
        "# Concatenate the outputs of the parallel Conv1D layers\n",
        "layer = keras.layers.Concatenate()(child_layers)\n",
        "\n",
        "# # Add a dropout layer to prevent overfitting\n",
        "# layer = keras.layers.Dropout(rate=0.3)(layer)\n",
        "\n",
        "# # Add a dense layer\n",
        "# layer = keras.layers.Dense(units=300, activation=\"relu\")(layer)\n",
        "\n",
        "# Output layer\n",
        "outputs = keras.layers.Dense(units=output_shape, activation=\"softmax\")(layer)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwVDYD6ZeWcM",
        "outputId": "884cd821-03ec-4166-f376-e0b93ab6b5a0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 3550\n",
            "Model: \"model_28\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_17 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " text_vectorization_16 (TextVec  (None, 50)          0           ['input_17[0][0]']               \n",
            " torization)                                                                                      \n",
            "                                                                                                  \n",
            " embedding_16 (Embedding)       (None, 50, 200)      710000      ['text_vectorization_16[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 50, 200)      0           ['embedding_16[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_19 (Reshape)           (None, 50, 200, 1)   0           ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " global_max_pooling2d_40 (Globa  (None, 1)           0           ['reshape_19[0][0]']             \n",
            " lMaxPooling2D)                                                                                   \n",
            "                                                                                                  \n",
            " global_max_pooling2d_41 (Globa  (None, 1)           0           ['reshape_19[0][0]']             \n",
            " lMaxPooling2D)                                                                                   \n",
            "                                                                                                  \n",
            " global_max_pooling2d_42 (Globa  (None, 1)           0           ['reshape_19[0][0]']             \n",
            " lMaxPooling2D)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 3)            0           ['global_max_pooling2d_40[0][0]',\n",
            "                                                                  'global_max_pooling2d_41[0][0]',\n",
            "                                                                  'global_max_pooling2d_42[0][0]']\n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 8)            32          ['concatenate_15[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 710,032\n",
            "Trainable params: 710,032\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessing.get_vocabulary()[:1000])"
      ],
      "metadata": {
        "id": "oQ6YmxqkkW_4",
        "outputId": "57c3fe91-3738-4a34-cf4c-54d269985433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', ' ', 'a', 'e', 'o', 't', 'i', 'n', 's', 'm', 'l', 'r', 'd', 'k', 'e  ', 'p', 'u', 'v', 'c', 'z', 'o  ', 'a  ', '  t', 'j', '  s', 'y', 'b', 'h', '  n', 't o', 'n e', '  p', 'm  ', '  a', 'i  ', 'a k', 'a l', '  m', 'n a', 't a', 'i e', '  z', 's t', 't e', 'p r', '  v', 's i', 'y  ', ',', 'l e', 'o m', ',  ', 'n i', 'p o', 'r a', 'j e', 'm a', 'r e', '?', 'k o', 'a t', 'e d', 't  ', '  d', 'f', '  j', 'o v', '  c', 'u  ', 'z e', 'e n', 'l  ', '  b', 'a m', 'a s', 'e s', 's a', 'r o', 'c h', 'i n', 'e m', 'd a', 'a n', 'd e', 'c i', 's  ', 'k  ', '  k', 'l a', 'v e', 'v i', 's o', 'e r', 't i', 'v a', 'n o', 'i s', 'd o', 'c o', 'r i', 'a v', '  o', 'o l', 'i t', 'o r', 'g', 'o d', 'h o', 'b o', '.', 'e l', 'l o', '  r', 'z  ', 'j a', 'l i', 'a c', 'o z', 'm e', 'n  ', 'k e', 'e c', 'z a', 'm i', 'j  ', 'a j', 'e t', 'o s', 'k a', 'e j', 'd  ', 's e', '0', '  i', 'e b', 'c e', 'm o', 'i a', '  u', 't r', 'o b', 'i l', 'a d', '  h', '1', 'o n', 'a z', 'i m', 's k', 'o t', 'v o', ':', 'i c', 'v y', 'd i', '  l', '   ', 'b y', 'k u', 'v  ', '/', 'u d', 'w', 'k y', 'x', '  f', ')', 'p i', '(', 'b u', 'd n', 's p', 'u s', 'o j', 't y', 's l', 't u', '2', 'o k', 'a p', 'o c', 'o o', 'a r', 'b a', 'n y', 'k t', 'u z', 'u j', 'n u', 'c a', 'm u', 'h  ', 'p a', 'i d', 'n t', 'h a', 'e z', 'e k', 'o h', 'u t', 'z i', 'i k', 'p l', 's u', 'z n', '-', 'e p', '\\n', '  e', 'b i', 'v s', 'l u', 'e v', 'h e', '3', 'l n', 'f a', 'y s', 'c  ', 'b e', 'i v', 'o u', 'r  ', 'a b', 'e ,', 'o p', '\"', 'p e', 'h l', 'd u', 'u l', 't n', 'v n', 'e ?', 'j o', '5', 'n d', 'c k', ': d', '  :', 'y c', 'r u', '  1', 'u n', 'd y', 'z d', 'j u', 'y t', 'm y', 'r y', 'u c', '4', 'a h', 'u p', 'b r', 't k', 'f o', 'u r', 'y m', 'h c', '.  ', 'k r', 'm n', 'k i', 'n g', 'z o', 'l k', '!', 'e a', 't h', '6', 'i b', 'd l', '@', 'n c', 's n', 'l y', 'e x', 'p s', 'f e', 'e e', 'r m', '9', '  2', '?  ', 'k l', 'c n', 'i p', 'a u', 'e h', 'n k', 'y z', 'b l', 'f i', ') )', '  (', 'e f', '0  ', '8', 'f u', 'a ,', 'p y', 'r t', 'h u', 'l l', 'h r', 'r v', '=', '0 0', 's m', '7', 'h y', 'h t', 'a i', '  g', 'g e', 'y p', 'u b', '  w', 'i z', '_', 'n s', '+', 'o g', 't t', '? ?', 't v', 'o ,', 'c u', 'r n', 'i o', '1 0', 'm p', 'd r', 'o ?', 'g r', 'u m', 'a ?', 'p t', 'd z', 't ,', 'l ,', 'm ,', 'u k', '. .', 'l s', 'r c', 'k d', 'd v', 'v r', 'z l', 'c t', 'z k', 'z m', 't p', ')  ', 't ?', 'z r', 'y ?', 'f  ', '  3', 's h', '*', 'd s', 'd p', 'y ,', '  \"', 'i u', 'a a', 'g u', 'p u', 'i ,', ': /', '  x', 'z v', 'g o', '/ /', 's s', 'q', '( (', 'j i', '2 0', 'm k', 'g i', 'r s', '  -', 'j t', 'x d', 'p  ', 'o f', 'z u', 'i ?', 'd k', 'm m', 'o w', 'a g', 'u e', '! !', 'u ,', 'y b', '>', 'h i', 'g  ', 'k z', 'u ?', 'j d', '2  ', 's :', '3  ', 's c', '  5', 'u h', 'j s', 't s', 'i h', 'r d', 'e o', 's y', 'v z', 'b  ', 'x  ', '\\\\', 'h n', 'e g', 'd m', '. 0', 't l', 'e .', 'c l', '5  ', 't c', '  4', 'v u', 'x t', 'i g', 'v l', 'r k', 'c s', 'u v', 'i i', 'b s', 'y e', 'c v', '1 .', '{', '#', 's v', 'k n', 's ?', 'l ?', 's ,', 'g a', '}', ':  ', 'k ,', '0 )', '=  ', 'z j', 'l m', 'n f', 'a .', '. c', '0 .', '\\n  ', 'i r', 'k c', 'j n', 'w o', 'w a', '  y', 'c r', '1  ', 'w i', 'o i', '  @', 'x i', 'i f', '%', '  =', 'w w', '( x', 'j ,', 'h m', '-  ', 'l t', '* (', 'y k', 'b n', ') ,', ') *', '4  ', 'l c', 'g l', 'w e', 't f', \"'\", 'k v', '[', ']', 'p h', 'm /', 'n n', 'm s', 'p n', 'm ?', 'y r', 'u a', '<', 'e u', '\"  ', 'r r', 'y o', 'n z', '  0', 'i j', '>  ', '. s', '/ w', 'v d', 'h d', '1 1', 'z h', 'x )', 'z p', '  6', 's .', '@ s', 'w h', 'p p', '@ f', 'z y', 'l h', '3 0', '\\n \\n', 'j m', 'r g', 'd c', 'p d', 'y h', '/ d', '6  ', 'w  ', 'k ?', 'm b', 't m', 'l g', 'q u', '( n', 'r z', 'a y', '( 1', 'v k', 's /', 'y l', 'k s', 'k /', 'd f', '/ s', 'm l', 'e w', 't .', 'p c', '1 2', 't w', 'a f', '2 .', 'z b', 'y n', 'f r', '@ d', '  9', 'd ,', 'b c', 'a o', 'r p', ';', 'd t', '5 0', 's r', 'l d', 'a x', '1 5', 'a 3', ': )', 'u i', 'f f', 'v c', '^', 'w .', 'v t', 'd (', 'p (', '0 2', '( 0', 'h ?', 'f l', 'n ,', 'u f', 'h v', 'w t', 'i x', '( a', 'b t', '  8', 'r l', '1 3', ') +', 'l b', 'd b', '/ p', 'r h', '+ (', 'r ,', '} \\n', 'f y', '- >', ') :', 'f m', 'r f', '  +', 'h s', '%  ', '0 1', '1 6', 'z s', 'n ?', 'g n', 'c ,', 'h ,', '7  ', '( p', '@ b', '. u', 'y .', 'u x', '/ m', 'o a', 'c c', '  <', '- 1', '1 4', '. 5', 'v ,', 'h .', 'y )', 'n .', 'e -', '  7', 'u u', 'u g', '. 1', '+  ', '8  ', 'y v', '. p', 'r .', 'g h', '1 7', 'r ?', 'n v', 'v p', 'l .', '. f', 'm t', '  q', 'n l', 'h k', ': 0', '+ +', 'z )', 'c ?', '1 ,', 'f t', 'e i', '/ c', 'd d', ': :', 'r b', 'l p', '1 8', '\\n \\\\', '9 9', 'l v', '2 1', '( y', 'k k', '3 .', 'v ?', 'e \"', '4 0', 'o .', '@ p', '2 ,', 'p :', 'd ?', '( z', 'f x', 'e )', '# #', '\\n a', 'c m', '/ a', '; \\n', '2 2', '/ f', 'z t', '0 ,', ') \\n', '  /', '  .', '0 %', 'm .', '\\n t', 'f p', 'e /', '/ 1', '|', 't d', '9  ', '. \\n', '&', '  \\\\', 'x p', 'e \\n', '_ b', '~', 'x o', 'm r', 'g /', '/ b', 'i .', 'a /', 'a )', 'b d', 'd h', '1 9', 'z ,', 'n b', 'e :', '2 6', '- s', '- p', 'j k', ']  ', '  [', ': (', '\" ,', 'j p', '1 )', '- -', 'w s', 'p k', 'j ?', '. o', 'e y', 'b m', '! 1', '  {', '\\n d', 'p ?', 'o (', '2 4', 't b', 'l z', '1 !', '  ?', 'w ,', 'd .', 'x e', 'e q', '2 5', 'u .', 'a -', '8 0', '. d', 'y u', '6 0', '/ e', 'g m', 'c y', '5 .', '\" n', '{ \\\\', '? !', '6 .', '. h', '. 2', 'x ,', 'j v', ': 1', '3 2', 'l f', '. g', ') ;', 'x y', 'j l', 'e _', 'b j', ') .', 'y i', '2 3', '/ g', 't /', 'a \"', '$', 'z c', 'g g', 'c p', '4 .', '/ t', '( t', '  #', 'd :', '- a', '( )', '  >', 'k m', 'k .', ': 3', '- c', 'c +', '/ v', '/ 2', '( s', '\" t', '\" a', 't (', 'p .', '\\n 1', 'm g', 'j h', '7 0', '6 4', '2 )', 'z ?', 't -', '4 ,', '/ r', 'y j', 'n )', 'd -', '9 0', '0 \\n', '- t', '\" p', 'w r', '9 .', '\\n p', 'h p', '/ l', \"' s\", 'z .', 'y y', 'v =', 'n -', 'd g', 'c .', '0 ?', '. y', '  |', 'n p', 'b b', 'b .', ': \\n', '0 3', 'i /', '? v', '1 :', '\\n c', 'y \"', 'f ,', 'c d', 'b ?', ': p', '3 ,', ', ,', 's -', 'p ,', 'f s', '4 5', '0 p', '( 2', 't 2', 's q', 'q  ', 'b ,', 'a \\n', '- w', 'y -', 'o /', 'c /', '2 8', '/ i', 'm >', '} {', 'w n', '_ c', '. m', '. i', '  *', '\\n h', 'y /', '_ s', '2 ?', '\" s', 't )', 'q l', 'o x', 'n ^', 'b v', '\\\\ t', '3 3', '3 1', '0 4', '. \"', '- o', 't \"', 's w', 'm h', '2 9', '1 /', 's )', 'n h', 'm f', 'g y', 'f (', 'e (', '\\\\ r', '? \"', '0 /', '0 -', 's \\n', 'p v', 'm c', 'i )', 'g b', '4 :', '3 5', '- 2', '( m', 'r :', 'e !', '3 7', '0 :', '0 6', '- r', 'x u', 'w c', 's d', 'n j', '- m', ', \\n', '+ 1', 's f', 'i -', 'g ,', '_ _', ': _', '4 8', '1 ?', '( k', 'y d', '8 .', '5 2', '- l', '- d', '\" m', '\\n s', '|  ', 'x c', 'u 2', 't \\n', 's z', 'f .', 'b )', '[ 1', '8 6', '0 5', '/ u', '/ n', '- n', 'u 1', 'g ?', 'g (', 'f ?', 'e {', 'a !', '^ 2', ': 5', '5 ,', '- b', '!  ', '{ }', 'y g', 'r -', 'p =', 'd _', 'd /', 'b h']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"fakin ak si nic nedas, tak PON UTO PIA mas???!? cely den na pracu a este streda poobede :D ðŸ‘ @fezjo\"\n",
        "\n",
        "inp = model.input                                           # input placeholder\n",
        "model_outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
        "functor = lambda outputs: keras.backend.function(inp, outputs)   # evaluation function\n",
        "\n",
        "# Testing\n",
        "for output in model_outputs:\n",
        "  print(functor([output])(np.array([sample_text])))"
      ],
      "metadata": {
        "id": "QeABB9LmasR9",
        "outputId": "d9e595c7-c7a3-46f4-aace-51d3cdb9d57c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[b'fakin ak si nic nedas, tak PON UTO PIA mas???!? cely den na pracu a este streda poobede :D \\xf0\\x9f\\x91\\x8d @fezjo']],\n",
            "      dtype=object)]\n",
            "[array([[  65,    3,   14,    7,    8,    2,    3,   14,    2,    9,    7,\n",
            "           2,    8,    7,   19,    2,    8,    4,   13,    3,    9,   49,\n",
            "           2,    6,    3,   14,    2,    1,    1,    1,    2,    1,    1,\n",
            "           1,    2,    1,    1,    1,    2,   10,    3,    9,   59,   59,\n",
            "          59,  268,   59,    2,   19,    4,   11,   26,    2,   13,    4,\n",
            "           8,    2,    8,    3,    2,   16,   12,    3,   19,   17,    2,\n",
            "           3,    2,    4,    9,    6,    4,    2,    9,    6,   12,    4,\n",
            "          13,    3,    2,   16,    5,    5,   27,    4,   13,    4,    2,\n",
            "         152,    1,    2,    1,    1,    1,    1,    2,  274,   65,    4,\n",
            "          20,   24,    5,  217,   36,  264,   80,  120,   34,   36,   87,\n",
            "          25,   47,   35,   29,   53,  153,  219,   29,   31,   62,   82,\n",
            "          75,  451,   52,   23,   40,   36,   87,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,   38,   57,   75,\n",
            "         449,  326,  326,  784, 1173,  285,   68,  136,  111,  277,   48,\n",
            "          64,   84,   71,  120,   29,   39,   22,   32,   45,   55,  117,\n",
            "         329,   69,   34,   22,  209,   76,   43,   44,   15,   25,   43,\n",
            "         140,   58,   62,   82,   22,   32,   54,  182,  141,  220,   62,\n",
            "          84,   15,  240,    1,    1,    1,    1,    1,    1,    1,  475,\n",
            "         530,  280,  197,  458,  235,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0]])]\n",
            "[array([[[-0.00336736, -0.05967908,  0.05660382, ...,  0.00603639,\n",
            "          0.016327  ,  0.07168494],\n",
            "        [ 0.04575608, -0.04738549, -0.06622662, ..., -0.04326603,\n",
            "         -0.05227714,  0.00292045],\n",
            "        [ 0.00852472,  0.07981013,  0.00144818, ...,  0.10897224,\n",
            "          0.1622151 , -0.06518926],\n",
            "        ...,\n",
            "        [ 0.03790474, -0.02639877, -0.01241523, ..., -0.0170439 ,\n",
            "         -0.04175155, -0.05486706],\n",
            "        [ 0.03790474, -0.02639877, -0.01241523, ..., -0.0170439 ,\n",
            "         -0.04175155, -0.05486706],\n",
            "        [ 0.03790474, -0.02639877, -0.01241523, ..., -0.0170439 ,\n",
            "         -0.04175155, -0.05486706]]], dtype=float32)]\n",
            "[array([[[-0.00336736, -0.05967908,  0.05660382, ...,  0.00603639,\n",
            "          0.016327  ,  0.07168494],\n",
            "        [ 0.04575608, -0.04738549, -0.06622662, ..., -0.04326603,\n",
            "         -0.05227714,  0.00292045],\n",
            "        [ 0.00852472,  0.07981013,  0.00144818, ...,  0.10897224,\n",
            "          0.1622151 , -0.06518926],\n",
            "        ...,\n",
            "        [ 0.03790474, -0.02639877, -0.01241523, ..., -0.0170439 ,\n",
            "         -0.04175155, -0.05486706],\n",
            "        [ 0.03790474, -0.02639877, -0.01241523, ..., -0.0170439 ,\n",
            "         -0.04175155, -0.05486706],\n",
            "        [ 0.03790474, -0.02639877, -0.01241523, ..., -0.0170439 ,\n",
            "         -0.04175155, -0.05486706]]], dtype=float32)]\n",
            "[array([[[[-0.00336736],\n",
            "         [-0.05967908],\n",
            "         [ 0.05660382],\n",
            "         ...,\n",
            "         [ 0.00603639],\n",
            "         [ 0.016327  ],\n",
            "         [ 0.07168494]],\n",
            "\n",
            "        [[ 0.04575608],\n",
            "         [-0.04738549],\n",
            "         [-0.06622662],\n",
            "         ...,\n",
            "         [-0.04326603],\n",
            "         [-0.05227714],\n",
            "         [ 0.00292045]],\n",
            "\n",
            "        [[ 0.00852472],\n",
            "         [ 0.07981013],\n",
            "         [ 0.00144818],\n",
            "         ...,\n",
            "         [ 0.10897224],\n",
            "         [ 0.1622151 ],\n",
            "         [-0.06518926]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.03790474],\n",
            "         [-0.02639877],\n",
            "         [-0.01241523],\n",
            "         ...,\n",
            "         [-0.0170439 ],\n",
            "         [-0.04175155],\n",
            "         [-0.05486706]],\n",
            "\n",
            "        [[ 0.03790474],\n",
            "         [-0.02639877],\n",
            "         [-0.01241523],\n",
            "         ...,\n",
            "         [-0.0170439 ],\n",
            "         [-0.04175155],\n",
            "         [-0.05486706]],\n",
            "\n",
            "        [[ 0.03790474],\n",
            "         [-0.02639877],\n",
            "         [-0.01241523],\n",
            "         ...,\n",
            "         [-0.0170439 ],\n",
            "         [-0.04175155],\n",
            "         [-0.05486706]]]], dtype=float32)]\n",
            "[array([[[[-0.32961434,  0.3799222 , -0.8851895 , ..., -0.40089396,\n",
            "          -0.79317206, -0.72477144]],\n",
            "\n",
            "        [[-0.88704795,  0.38722843, -0.54117936, ..., -0.01328247,\n",
            "          -0.8699455 , -0.5665256 ]],\n",
            "\n",
            "        [[-1.0526851 ,  0.14607263, -0.908301  , ..., -0.5080293 ,\n",
            "          -0.3706092 , -0.6991015 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.38273928,  0.8241916 , -1.1033992 , ..., -0.62199104,\n",
            "          -0.6017746 , -0.66904426]],\n",
            "\n",
            "        [[-0.38273928,  0.8241916 , -1.1033992 , ..., -0.62199104,\n",
            "          -0.6017746 , -0.66904426]],\n",
            "\n",
            "        [[-0.38273928,  0.8241916 , -1.1033992 , ..., -0.62199104,\n",
            "          -0.6017746 , -0.66904426]]]], dtype=float32)]\n",
            "[array([[[[ 0.28535515, -0.71716136, -0.7912824 , ..., -0.69019514,\n",
            "          -1.1975359 , -0.26561934]],\n",
            "\n",
            "        [[-0.23435038, -0.6571908 , -0.30242887, ..., -0.84067863,\n",
            "          -0.32418215, -0.8120792 ]],\n",
            "\n",
            "        [[-0.62825584, -0.40737814, -0.8827238 , ..., -0.760393  ,\n",
            "          -0.5983479 ,  0.3469779 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.9924252 , -0.63218987, -1.156192  , ..., -0.23565541,\n",
            "          -1.0026793 , -0.7418127 ]],\n",
            "\n",
            "        [[-0.9924252 , -0.63218987, -1.156192  , ..., -0.23565541,\n",
            "          -1.0026793 , -0.7418127 ]],\n",
            "\n",
            "        [[-0.9924252 , -0.63218987, -1.156192  , ..., -0.23565541,\n",
            "          -1.0026793 , -0.7418127 ]]]], dtype=float32)]\n",
            "[array([[[[-0.2654069 ,  0.29454258, -0.21525961, ..., -0.06443822,\n",
            "          -0.7097507 ,  1.413919  ]],\n",
            "\n",
            "        [[-1.0992801 ,  0.3216189 , -0.8178016 , ...,  1.2223938 ,\n",
            "          -1.1453663 , -1.4171327 ]],\n",
            "\n",
            "        [[-1.3958006 ,  0.21648782, -0.5211573 , ...,  0.01405858,\n",
            "          -0.74763924, -0.67788154]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.2210127 ,  1.251364  ,  0.38029593, ...,  0.6487622 ,\n",
            "          -1.0843464 , -0.81825453]],\n",
            "\n",
            "        [[-1.2210127 ,  1.251364  ,  0.38029593, ...,  0.6487622 ,\n",
            "          -1.0843464 , -0.81825453]],\n",
            "\n",
            "        [[-1.2210127 ,  1.251364  ,  0.38029593, ...,  0.6487622 ,\n",
            "          -1.0843464 , -0.81825453]]]], dtype=float32)]\n",
            "[array([[1.3679557, 1.6426549, 1.6578481, 1.6503346, 1.7730714, 1.7159269,\n",
            "        1.4649177, 1.0876361, 0.6284046, 0.6299143, 1.1401885, 0.7528687,\n",
            "        2.3303418, 0.9361261, 0.78385  , 1.051766 , 1.4206966, 1.0925558,\n",
            "        2.4257958, 1.0078036]], dtype=float32)]\n",
            "[array([[1.3585984 , 0.64371014, 1.4485177 , 1.7153976 , 1.743104  ,\n",
            "        1.8947451 , 1.625427  , 2.4434628 , 1.7256011 , 2.435738  ,\n",
            "        1.2410334 , 1.4807782 , 2.4940069 , 1.1306651 , 1.4477894 ,\n",
            "        1.6277001 , 2.1094627 , 1.3697281 , 2.232149  , 1.3532162 ]],\n",
            "      dtype=float32)]\n",
            "[array([[0.84400547, 1.251364  , 2.4278095 , 1.3539764 , 1.5475363 ,\n",
            "        1.2707957 , 0.8479627 , 2.2608304 , 2.6194143 , 1.6040782 ,\n",
            "        0.8894697 , 1.3417308 , 1.662754  , 0.65155405, 1.3115079 ,\n",
            "        1.2146504 , 1.3817637 , 1.2223938 , 2.2923853 , 2.3745694 ]],\n",
            "      dtype=float32)]\n",
            "[array([[1.3679557 , 1.6426549 , 1.6578481 , 1.6503346 , 1.7730714 ,\n",
            "        1.7159269 , 1.4649177 , 1.0876361 , 0.6284046 , 0.6299143 ,\n",
            "        1.1401885 , 0.7528687 , 2.3303418 , 0.9361261 , 0.78385   ,\n",
            "        1.051766  , 1.4206966 , 1.0925558 , 2.4257958 , 1.0078036 ,\n",
            "        1.3585984 , 0.64371014, 1.4485177 , 1.7153976 , 1.743104  ,\n",
            "        1.8947451 , 1.625427  , 2.4434628 , 1.7256011 , 2.435738  ,\n",
            "        1.2410334 , 1.4807782 , 2.4940069 , 1.1306651 , 1.4477894 ,\n",
            "        1.6277001 , 2.1094627 , 1.3697281 , 2.232149  , 1.3532162 ,\n",
            "        0.84400547, 1.251364  , 2.4278095 , 1.3539764 , 1.5475363 ,\n",
            "        1.2707957 , 0.8479627 , 2.2608304 , 2.6194143 , 1.6040782 ,\n",
            "        0.8894697 , 1.3417308 , 1.662754  , 0.65155405, 1.3115079 ,\n",
            "        1.2146504 , 1.3817637 , 1.2223938 , 2.2923853 , 2.3745694 ]],\n",
            "      dtype=float32)]\n",
            "[array([[1.6997937e-02, 5.3510543e-02, 6.7747608e-02, 7.4265361e-02,\n",
            "        7.8164387e-01, 5.3098453e-03, 1.0585457e-04, 4.1897889e-04]],\n",
            "      dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(**{\n",
        "    \"x\": X_train,\n",
        "    \"y\": keras.utils.to_categorical(Y_train),\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 64,\n",
        "    \"validation_split\": 0.10,\n",
        "    \"verbose\": 1,\n",
        "    })\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "33v51oypOQxY",
        "outputId": "2a7fa70d-23fb-4b29-ed7c-b923b444f84b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "716/716 [==============================] - 5s 6ms/step - loss: 1.7430 - accuracy: 0.2744 - val_loss: 1.6214 - val_accuracy: 0.2840\n",
            "Epoch 2/10\n",
            "716/716 [==============================] - 4s 6ms/step - loss: 1.5805 - accuracy: 0.2798 - val_loss: 1.5916 - val_accuracy: 0.2840\n",
            "Epoch 3/10\n",
            "716/716 [==============================] - 4s 6ms/step - loss: 1.5756 - accuracy: 0.2879 - val_loss: 1.5894 - val_accuracy: 0.2840\n",
            "Epoch 4/10\n",
            "716/716 [==============================] - 4s 6ms/step - loss: 1.5748 - accuracy: 0.2866 - val_loss: 1.5893 - val_accuracy: 0.2840\n",
            "Epoch 5/10\n",
            "715/716 [============================>.] - ETA: 0s - loss: 1.5746 - accuracy: 0.2851"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-8e07fe58d559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(**{\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1446\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = model.evaluate(X_train, tf.keras.utils.to_categorical(Y_train))\n",
        "print(\"\\n\\ntrain loss: {} | train acc: {}\\n\".format(train_score[0], train_score[1]))\n",
        "\n",
        "test_score = model.evaluate(X_test, tf.keras.utils.to_categorical(Y_test))\n",
        "print(\"\\n\\ntest loss: {} | test acc: {}\".format(test_score[0], test_score[1]))"
      ],
      "metadata": {
        "id": "PGuGYSdyzP0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}